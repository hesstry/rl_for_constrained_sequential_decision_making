# rl_for_constrained_sequential_decision_making
Description in title, a small project I did for ListenLabs where I decided to learn how to create my own custom RL environment and devise an appropriate reward-based shaping signal to beat GPT-5, it was a success.

Included in `rl_agent_puzzle_II.ipynb` are all of my environment code, synthetic data creation, and analysis + visualizations on reward signal effects for goal completion.

Included in `test_model_on_puzzle.ipynb` is the trained model put to the test on the actual puzzle, beating GPT-5 on the leaderboard.
